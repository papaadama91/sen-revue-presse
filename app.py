import streamlit as st
from PyPDF2 import PdfReader
from docx import Document as DocxDocument
import os
import re
from transformers import pipeline
from collections import defaultdict
from deep_translator import GoogleTranslator
from gtts import gTTS
from doctr.io import DocumentFile
from doctr.models import ocr_predictor

@st.cache_resource
def load_summarizer():
    return pipeline("summarization", model="facebook/bart-large-cnn")

@st.cache_resource
def load_ocr_model():
    return ocr_predictor(pretrained=True)

summarizer = load_summarizer()
ocr_model = load_ocr_model()

def extract_text(file):
    ext = os.path.splitext(file.name)[-1].lower()
    if ext in [".jpg", ".jpeg", ".png", ".pdf"]:
        doc = DocumentFile.from_pdf(file) if ext == ".pdf" else DocumentFile.from_images(file)
        result = ocr_model(doc)
        return result.export()["value"]
    elif ext == ".docx":
        doc = DocxDocument(file)
        return "\n".join([p.text for p in doc.paragraphs])
    elif ext == ".txt":
        return file.read().decode("utf-8")
    else:
        return ""

def extract_metadata(text):
    title = text.strip().split("\n")[0][:80]
    date_match = re.search(r'\d{1,2} \w+ \d{4}', text)
    date = date_match.group() if date_match else "Date inconnue"
    return title, date

def classify_article(text):
    keywords = {
        "Politique": ["pr√©sident", "gouvernement", "√©lection"],
        "√âconomie": ["croissance", "pib", "bourse", "march√©", "inflation"],
        "Soci√©t√©": ["√©ducation", "sant√©", "social", "famille", "logement"],
        "Culture": ["musique", "cin√©ma", "livre", "art", "festival"],
        "Sport": ["football", "match", "jo", "ligue", "comp√©tition"]
    }
    for theme, mots in keywords.items():
        if any(mot in text.lower() for mot in mots):
            return theme
    return "Autres"

def summarize_text(text):
    try:
        return summarizer(text[:1024], max_length=100, min_length=30, do_sample=False)[0]['summary_text']
    except:
        return "R√©sum√© non disponible."

def translate_to_wolof(text):
    try:
        return GoogleTranslator(source='fr', target='sn').translate(text)
    except:
        return "[Traduction indisponible]"

def generate_voiceover_script(articles_by_theme, translate=False):
    script = ""
    for theme, articles in articles_by_theme.items():
        script += f"\nüóÇÔ∏è {theme}\n"
        for art in articles:
            phrase = f"Le {art['date']}, un m√©dia local a rapport√© : {art['resume']}\n"
            if translate:
                phrase = translate_to_wolof(phrase)
            script += phrase
    return script.strip()

def generate_audio_fr(text, filename="voix_off_fr.mp3"):
    tts = gTTS(text=text, lang="fr")
    tts.save(filename)
    return filename

from docx import Document as DocxDocumentExport
def generate_docx_by_theme(articles_by_theme):
    doc = DocxDocumentExport()
    doc.add_heading("Revue de Presse Th√©matique", 0)
    for theme, articles in articles_by_theme.items():
        doc.add_heading(f"Th√®me : {theme}", level=1)
        for art in articles:
            doc.add_heading(art['titre'], level=2)
            doc.add_paragraph(f"Date : {art['date']}")
            doc.add_paragraph("R√©sum√© :")
            doc.add_paragraph(art['resume'])
            doc.add_paragraph("---")
    path = "revue_presse.docx"
    doc.save(path)
    return path

# Interface Streamlit
st.title("üì∞ G√©n√©rateur de Revue de Presse Th√©matique (DocTR OCR)")
st.markdown("Charge tes fichiers presse ci-dessous (.pdf, .docx, .txt, .png, .jpg)")

uploaded_files = st.file_uploader("Fichiers :", accept_multiple_files=True, type=["pdf", "docx", "txt", "png", "jpg", "jpeg"])

if uploaded_files:
    articles_by_theme = defaultdict(list)
    with st.spinner("Analyse des fichiers en cours..."):
        for file in uploaded_files:
            text = extract_text(file)
            titre, date = extract_metadata(text)
            theme = classify_article(text)
            resume = summarize_text(text)
            article = {"titre": titre, "date": date, "theme": theme, "resume": resume}
            articles_by_theme[theme].append(article)

    if articles_by_theme:
        docx_path = generate_docx_by_theme(articles_by_theme)
        st.success("‚úÖ Revue de presse g√©n√©r√©e.")
        with open(docx_path, "rb") as f:
            st.download_button("üì• T√©l√©charger Word", f, file_name="revue_presse.docx")

        st.subheader("üéôÔ∏è Script Voix-Off (Fran√ßais)")
        fr_script = generate_voiceover_script(articles_by_theme)
        st.text_area("Script FR", fr_script, height=300)

        st.subheader("üåç Script Voix-Off (Wolof)")
        wo_script = generate_voiceover_script(articles_by_theme, translate=True)
        st.text_area("Script WO", wo_script, height=300)

        st.download_button("üì§ T√©l√©charger Script FR", fr_script, file_name="script_voixoff_fr.txt")
        st.download_button("üì§ T√©l√©charger Script WO", wo_script, file_name="script_voixoff_wolof.txt")

        if st.button("üîâ G√©n√©rer voix-off FR (MP3)"):
            audio_path = generate_audio_fr(fr_script)
            with open(audio_path, "rb") as audio_file:
                st.audio(audio_file.read(), format="audio/mp3")
                st.download_button("üì• T√©l√©charger MP3", audio_file, file_name="voix_off_fr.mp3")
